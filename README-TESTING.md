# ğŸ§ª Guide de Tests E2E - AI App Builder

Ce guide explique comment configurer et utiliser le systÃ¨me de tests automatisÃ©s qui simule un humain interagissant avec votre AI App Builder.

## ğŸ“‹ Table des MatiÃ¨res

- [Vue d'ensemble](#vue-densemble)
- [Installation](#installation)
- [Configuration](#configuration)
- [Utilisation](#utilisation)
- [Services Externes](#services-externes)
- [DÃ©pannage](#dÃ©pannage)

## ğŸ¯ Vue d'ensemble

Le systÃ¨me de tests E2E simule un humain qui :
- Ouvre l'application
- Clique dans l'Ã©diteur de prompts
- Tape ou colle un prompt
- Attend la gÃ©nÃ©ration/rÃ©ponse
- VÃ©rifie que l'Ã©diteur s'active
- ContrÃ´le que la sortie attendue apparaÃ®t

### Stack Technologique

- **Playwright** : Tests E2E avec simulation humaine
- **LangSmith** : Ã‰valuation et tracing des rÃ©ponses LLM
- **Percy** : Tests visuels et comparaisons
- **BrowserStack** : Tests cross-device
- **GitHub Actions** : CI/CD automatisÃ©

## ğŸš€ Installation

### 1. Installer les dÃ©pendances

```bash
# Installer les dÃ©pendances principales
npm install

# Installer les dÃ©pendances de test
cd packages/ci
npm install

# Installer les navigateurs Playwright
npx playwright install --with-deps
```

### 2. Structure des fichiers

```
packages/ci/
â”œâ”€â”€ playwright.config.ts          # Configuration Playwright
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ e2e/
â”‚   â”‚   â”œâ”€â”€ prompt-editor.spec.ts # Tests principaux
â”‚   â”‚   â””â”€â”€ prompt-eval.js        # Ã‰valuation LangSmith
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ langsmith-evaluator.ts
â”‚   â”‚   â””â”€â”€ visual-snapshot.ts
â”‚   â”œâ”€â”€ global-setup.ts
â”‚   â””â”€â”€ global-teardown.ts
â””â”€â”€ package.json

.github/workflows/
â””â”€â”€ ai_ui_test.yml                # Workflow GitHub Actions
```

## âš™ï¸ Configuration

### 1. Variables d'environnement

CrÃ©ez un fichier `.env` dans `packages/ci/` :

```env
# Application
BASE_URL=http://localhost:3000
HEADLESS=false

# LangSmith
LANGSMITH_API_KEY=your_langsmith_api_key
LANGSMITH_PROJECT=ai-app-builder-evals

# OpenAI
OPENAI_API_KEY=your_openai_api_key

# Percy (optionnel)
PERCY_TOKEN=your_percy_token
PERCY_PROJECT=ai-app-builder

# BrowserStack (optionnel)
BROWSERSTACK_USERNAME=your_browserstack_username
BROWSERSTACK_ACCESS_KEY=your_browserstack_access_key

# Applitools (optionnel)
APPLITOOLS_API_KEY=your_applitools_api_key
```

### 2. SÃ©lecteurs de l'application

Modifiez les sÃ©lecteurs dans `tests/e2e/prompt-editor.spec.ts` selon votre application :

```typescript
// SÃ©lecteurs par dÃ©faut (Ã  adapter)
'[data-testid="app-container"]'     // Conteneur principal
'[data-testid="new-app-button"]'    // Bouton nouvelle app
'[data-testid="prompt-editor"]'     // Ã‰diteur de prompts
'[data-testid="generate-button"]'   // Bouton gÃ©nÃ©ration
'[data-testid="code-editor"]'       // Ã‰diteur de code
'[data-testid="generation-status"]' // Statut de gÃ©nÃ©ration
```

### 3. Configuration Playwright

Le fichier `playwright.config.ts` est prÃ©-configurÃ© pour :
- Tests sur Chrome, Firefox, Safari
- Tests sur mobile (iPhone, Pixel)
- Capture de traces, vidÃ©os, screenshots
- IntÃ©gration avec les services externes

## ğŸ® Utilisation

### 1. Tests locaux

```bash
# Tests complets
cd packages/ci
npm run test:e2e

# Tests spÃ©cifiques
npx playwright test --grep="prompt-editor"

# Tests avec interface graphique
npx playwright test --ui

# Tests sur un navigateur spÃ©cifique
npx playwright test --project=chromium
```

### 2. Tests en mode debug

```bash
# Mode debug avec interface
npx playwright test --debug

# Mode debug avec console
npx playwright test --headed --debug
```

### 3. Tests de performance

```bash
# Tests de performance
npx playwright test --grep="performance"

# Tests avec mÃ©triques
npx playwright test --grep="performance" --reporter=html
```

### 4. Tests visuels

```bash
# Tests visuels avec Percy
npx playwright test --grep="visual"

# Tests avec Applitools
npx playwright test --grep="visual" --reporter=applitools
```

## ğŸ”§ Services Externes

### LangSmith

1. **CrÃ©er un compte** : [smith.langchain.com](https://smith.langchain.com)
2. **Obtenir la clÃ© API** : Settings â†’ API Keys
3. **Configurer le projet** : CrÃ©er un projet "ai-app-builder-evals"
4. **Ajouter la clÃ©** : `LANGSMITH_API_KEY` dans les secrets GitHub

**FonctionnalitÃ©s** :
- Ã‰valuation automatique des rÃ©ponses LLM
- Scoring de qualitÃ© du code gÃ©nÃ©rÃ©
- Tracing des interactions
- MÃ©triques de performance

### Percy

1. **CrÃ©er un compte** : [percy.io](https://percy.io)
2. **Obtenir le token** : Settings â†’ Project Settings
3. **Configurer le projet** : CrÃ©er un projet "ai-app-builder"
4. **Ajouter le token** : `PERCY_TOKEN` dans les secrets GitHub

**FonctionnalitÃ©s** :
- Tests visuels automatiques
- Comparaison de snapshots
- DÃ©tection de rÃ©gressions visuelles
- Rapports visuels dÃ©taillÃ©s

### BrowserStack

1. **CrÃ©er un compte** : [browserstack.com](https://browserstack.com)
2. **Obtenir les credentials** : Account â†’ Settings
3. **Configurer l'accÃ¨s** : Automate â†’ Access Key
4. **Ajouter les credentials** : `BROWSERSTACK_USERNAME` et `BROWSERSTACK_ACCESS_KEY`

**FonctionnalitÃ©s** :
- Tests sur de vrais appareils
- Tests cross-browser
- Tests sur diffÃ©rentes rÃ©solutions
- Tests de performance mobile

## ğŸ“Š Rapports et RÃ©sultats

### 1. Rapports locaux

```bash
# Ouvrir le rapport HTML
npx playwright show-report

# Consulter les rÃ©sultats
open test-results/final-report.html
```

### 2. Artefacts gÃ©nÃ©rÃ©s

- **Screenshots** : `test-results/screenshots/`
- **VidÃ©os** : `test-results/videos/`
- **Traces** : `test-results/traces/`
- **Rapports** : `test-results/reports/`

### 3. MÃ©triques d'Ã©valuation

Le systÃ¨me Ã©value automatiquement :
- **QualitÃ© du code** (0-1)
- **ComplÃ©tude** (0-1)
- **Bonnes pratiques** (0-1)
- **Usage TypeScript** (0-1)
- **Patterns React** (0-1)
- **SÃ©curitÃ©** (0-1)
- **Performance** (0-1)
- **AccessibilitÃ©** (0-1)
- **Tests** (0-1)

## ğŸš¨ DÃ©pannage

### ProblÃ¨mes courants

#### 1. Application non accessible

```bash
# VÃ©rifier que l'application est dÃ©marrÃ©e
curl http://localhost:3000

# VÃ©rifier les logs
npm run dev
```

#### 2. SÃ©lecteurs non trouvÃ©s

```bash
# Inspecter les sÃ©lecteurs
npx playwright test --debug

# Utiliser le mode headed
npx playwright test --headed
```

#### 3. Tests lents

```bash
# RÃ©duire le nombre de workers
npx playwright test --workers=1

# DÃ©sactiver les captures
npx playwright test --video=off --screenshot=off
```

#### 4. Erreurs LangSmith

```bash
# VÃ©rifier la clÃ© API
echo $LANGSMITH_API_KEY

# Tester la connexion
curl -H "Authorization: Bearer $LANGSMITH_API_KEY" \
     https://api.smith.langchain.com/projects
```

### Logs et debugging

```bash
# Activer les logs dÃ©taillÃ©s
DEBUG=pw:api npx playwright test

# Capturer les traces
npx playwright test --trace=on

# Mode debug interactif
npx playwright test --debug
```

## ğŸ“ˆ AmÃ©lioration continue

### 1. Ajouter de nouveaux tests

```typescript
// Dans prompt-editor.spec.ts
test('Nouveau scÃ©nario de test', async ({ page }) => {
  // Votre test ici
});
```

### 2. Personnaliser les Ã©valuations

```typescript
// Dans langsmith-evaluator.ts
async evaluateCustom(params: {
  prompt: string;
  response: string;
  customCriteria: string[];
}) {
  // Votre logique d'Ã©valuation
}
```

### 3. Ajouter des mÃ©triques

```typescript
// Dans visual-snapshot.ts
async captureWithMetrics(name: string) {
  // Capturer avec mÃ©triques personnalisÃ©es
}
```

## ğŸ¤ Contribution

1. **Fork** le repository
2. **CrÃ©er** une branche feature
3. **Ajouter** vos tests
4. **VÃ©rifier** que tous les tests passent
5. **Soumettre** une pull request

## ğŸ“ Support

- **Issues** : [GitHub Issues](https://github.com/your-repo/issues)
- **Documentation** : [Wiki](https://github.com/your-repo/wiki)
- **Discussions** : [GitHub Discussions](https://github.com/your-repo/discussions)

---

**ğŸ‰ FÃ©licitations !** Votre systÃ¨me de tests E2E est maintenant configurÃ© et prÃªt Ã  simuler un humain interagissant avec votre AI App Builder.
